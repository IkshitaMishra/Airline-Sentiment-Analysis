{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import datetime as dt\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\Users\\Ikshita\\Downloads\\Projs\\TextPreprocessing\\Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@virginamerica @virginmedia i'm flying your #fabulous #seductive skies again! u take all the #stress away from travel http://t.co/ahlxhhkiyn\n"
     ]
    }
   ],
   "source": [
    "#remove any rows that has no tweet text\n",
    "df =data.iloc[:,[1,2,10]]\n",
    "df = df.dropna(axis=0, subset=['text'])\n",
    "#Create dictionary of all tweets\n",
    "tweetdict = {}\n",
    "i = 0\n",
    "for line in df.text:\n",
    "    tweetdict[i] = line.lower().strip()\n",
    "    i=i+1\n",
    "print(tweetdict[13])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove @ Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm flying your #fabulous #seductive skies again! u take all the #stress away from travel http://t.co/ahlxhhkiyn\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(tweetdict)):\n",
    "    words = tweetdict[i].split(\" \")\n",
    "    no_mention = [ x for x in words if \"@\" not in x ]\n",
    "    no_mention = ' '.join(map(str, no_mention))\n",
    "    tweetdict[i] = no_mention\n",
    "print(tweetdict[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove # Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm flying your skies again! u take all the away from travel http://t.co/ahlxhhkiyn\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(tweetdict)):\n",
    "    words = tweetdict[i].split(\" \")\n",
    "    no_mention = [ x for x in words if \"#\" not in x ]\n",
    "    tweetdict[i] = ' '.join(map(str, no_mention))\n",
    "print(tweetdict[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Hyperlinks and Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i m flying your skies again u take all the away from travel \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(tweetdict)):\n",
    "    tweetdict[i] = re.sub(r'((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', '', tweetdict[i], flags=re.MULTILINE)\n",
    "    tweetdict[i] = re.sub('\\W+', ' ', tweetdict[i]) #Jus keep letters and numbers\n",
    "    tweetdict[i] = re.sub('\\d+', ' ', tweetdict[i]) #Remove numbers\n",
    "print(tweetdict[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove 'RT' Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    tweetdict[i] = tweetdict[i].replace('RT', '').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'm', 'flying', 'your', 'skies', 'again', 'u', 'take', 'all', 'the', 'away', 'from', 'travel']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(tweetdict)):\n",
    "    tweetdict[i] = WhitespaceTokenizer().tokenize(tweetdict[i])\n",
    "print(tweetdict[13]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'm', 'flying', 'your', 'sky', 'again', 'u', 'take', 'all', 'the', 'away', 'from', 'travel']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(0,len(tweetdict)):\n",
    "    words = tweetdict[i]\n",
    "    for index, word in enumerate(words):\n",
    "        words[index] = lemmatizer.lemmatize(word)\n",
    "        tweetdict[i] = words\n",
    "print(tweetdict[13])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flying sky u take away travel\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stopwords = list(stopwords.words('english'))\n",
    "for i in range(0,len(tweetdict)):\n",
    "    nostp = [word for word in tweetdict[i] if word.lower() not in en_stopwords]\n",
    "    tweetdict[i] = ' '.join(map(str, nostp))\n",
    "print(tweetdict[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=[]\n",
    "for i in range(0,len(tweetdict)):\n",
    "    tweets.append(tweetdict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>wtf</th>\n",
       "      <th>yall</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1075 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  able  absolute  absolutely  accept  acceptable  access  accommodate  \\\n",
       "0  0.0   0.0       0.0         0.0     0.0         0.0     0.0          0.0   \n",
       "1  0.0   0.0       0.0         0.0     0.0         0.0     0.0          0.0   \n",
       "2  0.0   0.0       0.0         0.0     0.0         0.0     0.0          0.0   \n",
       "3  0.0   0.0       0.0         0.0     0.0         0.0     0.0          0.0   \n",
       "4  0.0   0.0       0.0         0.0     0.0         0.0     0.0          0.0   \n",
       "\n",
       "   account  act  ...   wtf  yall  yeah  year  yep  yes  yesterday   yo   yr  \\\n",
       "0      0.0  0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0        0.0  0.0  0.0   \n",
       "1      0.0  0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0        0.0  0.0  0.0   \n",
       "2      0.0  0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0        0.0  0.0  0.0   \n",
       "3      0.0  0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0        0.0  0.0  0.0   \n",
       "4      0.0  0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0        0.0  0.0  0.0   \n",
       "\n",
       "   zero  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 1075 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(strip_accents=None,\n",
    "                            max_df=0.8,\n",
    "                            min_df=15,\n",
    "                            lowercase=True,\n",
    "                            stop_words=\"english\",\n",
    "                            sublinear_tf=True,\n",
    "                            analyzer='word')\n",
    "dtm = vect.fit_transform(tweets) \n",
    "# create Document Term Matrix\n",
    "df_dtm = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())\n",
    "df_dtm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>aa</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>...</th>\n",
       "      <th>wtf</th>\n",
       "      <th>yall</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1077 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  retweet_count   aa  able  absolute  absolutely  accept  \\\n",
       "0           neutral              0  0.0   0.0       0.0         0.0     0.0   \n",
       "1          positive              0  0.0   0.0       0.0         0.0     0.0   \n",
       "2           neutral              0  0.0   0.0       0.0         0.0     0.0   \n",
       "3          negative              0  0.0   0.0       0.0         0.0     0.0   \n",
       "4          negative              0  0.0   0.0       0.0         0.0     0.0   \n",
       "\n",
       "   acceptable  access  accommodate  ...   wtf  yall  yeah  year  yep  yes  \\\n",
       "0         0.0     0.0          0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0   \n",
       "1         0.0     0.0          0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0   \n",
       "2         0.0     0.0          0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0   \n",
       "3         0.0     0.0          0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0   \n",
       "4         0.0     0.0          0.0  ...   0.0   0.0   0.0   0.0  0.0  0.0   \n",
       "\n",
       "   yesterday   yo   yr  zero  \n",
       "0        0.0  0.0  0.0   0.0  \n",
       "1        0.0  0.0  0.0   0.0  \n",
       "2        0.0  0.0  0.0   0.0  \n",
       "3        0.0  0.0  0.0   0.0  \n",
       "4        0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 1077 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels =data.iloc[:,[1,9]]\n",
    "datafr = pd.concat([df_labels.reset_index(drop=True),df_dtm.reset_index(drop=True)], axis=1)\n",
    "datafr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score ,confusion_matrix,recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['negative' 'neutral' 'neutral' ..., 'neutral' 'negative' 'negative']\n",
      "Correct:     ['neutral' 'positive' 'neutral' ..., 'negative' 'negative' 'negative']\n",
      "Confusion Matrix:\n",
      "[[1515  258  126]\n",
      " [ 252  251   82]\n",
      " [ 140   72  232]]\n",
      "Accuracy is: 68.238\n",
      "Precision : [ 0.79444153  0.43201377  0.52727273]\n",
      "Recall : [ 0.79778831  0.42905983  0.52252252]\n",
      "F1-Score :  [ 0.7961114   0.43053173  0.52488688]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'neutral' 'neutral']\n",
      "Correct:     ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1336  236  128]\n",
      " [ 324  283   79]\n",
      " [ 162  103  277]]\n",
      "Accuracy is: 64.754\n",
      "Precision : [ 0.73326015  0.45498392  0.57231405]\n",
      "Recall : [ 0.78588235  0.41253644  0.51107011]\n",
      "F1-Score :  [ 0.75865985  0.43272171  0.53996101]\n",
      "===============================================================================\n",
      "Prediction:  ['positive' 'negative' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Correct:     ['neutral' 'neutral' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[1003  220   66]\n",
      " [ 383  414  120]\n",
      " [ 231  129  362]]\n",
      "Accuracy is: 60.758\n",
      "Precision : [ 0.62028448  0.54259502  0.66058394]\n",
      "Recall : [ 0.77812258  0.45147219  0.50138504]\n",
      "F1-Score :  [ 0.69029594  0.49285714  0.57007874]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'positive']\n",
      "Correct:     ['negative' 'neutral' 'negative' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[1783  283  137]\n",
      " [ 203  169   57]\n",
      " [  80   30  186]]\n",
      "Accuracy is: 73.019\n",
      "Precision : [ 0.86302033  0.35062241  0.48947368]\n",
      "Recall : [ 0.80935089  0.39393939  0.62837838]\n",
      "F1-Score :  [ 0.83532443  0.37102086  0.55029586]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'positive' ..., 'positive' 'negative' 'negative']\n",
      "Correct:     ['negative' 'negative' 'positive' ..., 'neutral' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1652  313  122]\n",
      " [ 200  213   69]\n",
      " [ 109   49  201]]\n",
      "Accuracy is: 70.560\n",
      "Precision : [ 0.84242733  0.37043478  0.5127551 ]\n",
      "Recall : [ 0.79156684  0.44190871  0.55988858]\n",
      "F1-Score :  [ 0.81620553  0.40302744  0.53528628]\n",
      "Average Accuracy: 67.466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.79      0.79      9178\n",
      "    neutral       0.44      0.43      0.43      3099\n",
      "   positive       0.56      0.53      0.55      2363\n",
      "\n",
      "avg / total       0.67      0.67      0.67     14640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "x = datafr.values[:,1:]                                                     # retweet_count + Doc-Term Matrix\n",
    "y = datafr.values[:,0]                                                      # airline_sentiment\n",
    "kf = KFold(n_splits=5)                                                     # K-Folds = 10 \n",
    "kf.get_n_splits(x)\n",
    "accuracy=[]\n",
    "yt = []\n",
    "yp = []\n",
    "for train_index, test_index in kf.split(x):                                 # For each train and test data\n",
    "    x_train, x_test = x[train_index], x[test_index]                                   \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    sc_x=StandardScaler()\n",
    "    x_train=sc_x.fit_transform(x_train)\n",
    "    x_test=sc_x.transform(x_test)\n",
    "    classifier =DecisionTreeClassifier(criterion='entropy')                  # Decision Tree Classifier\n",
    "    classifier.fit(x_train,y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    print('===============================================================================')\n",
    "    print('Prediction: ', y_pred)\n",
    "    print('Correct:    ', y_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    acc= accuracy_score(y_test,y_pred)*100\n",
    "    print(\"Accuracy is: %0.3f\" % acc)                                        # Accuracy in each 10 folds\n",
    "    accuracy.append(acc)\n",
    "    pr = precision_score(y_test, y_pred,average=None)\n",
    "    print(\"Precision :\", pr)                                                 # Precision in each 10 folds\n",
    "    recscr = recall_score(y_test, y_pred,average=None)\n",
    "    print(\"Recall :\",  recscr)                                               # Recall in each 10 folds\n",
    "    f1 = f1_score(y_test, y_pred,average=None)\n",
    "    print(\"F1-Score : \",  f1)                                                # F1-Score in each 10 folds\n",
    "    yt += list(y_test)\n",
    "    yp += list(y_pred)\n",
    "\n",
    "avg_accu = np.mean(accuracy)\n",
    "print(\"Average Accuracy: %0.3f\" % avg_accu)                                  # Average Accuracy across 10 folds\n",
    "print(classification_report(yt, yp))                                         # Average Accuracy Precision Recall F1-Score across 10 folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'negative']\n",
      "Correct:     ['neutral' 'positive' 'neutral' ..., 'negative' 'negative' 'negative']\n",
      "Confusion Matrix:\n",
      "[[1692  147   60]\n",
      " [ 279  257   49]\n",
      " [ 158   51  235]]\n",
      "Accuracy is: 74.590\n",
      "Precision : [ 0.79473931  0.56483516  0.68313953]\n",
      "Recall : [ 0.89099526  0.43931624  0.52927928]\n",
      "F1-Score :  [ 0.84011917  0.49423077  0.5964467 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'neutral' 'neutral']\n",
      "Correct:     ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1534  103   63]\n",
      " [ 348  274   64]\n",
      " [ 202   68  272]]\n",
      "Accuracy is: 71.038\n",
      "Precision : [ 0.73608445  0.61573034  0.68170426]\n",
      "Recall : [ 0.90235294  0.39941691  0.50184502]\n",
      "F1-Score :  [ 0.81078224  0.48452697  0.5781084 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['positive' 'negative' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Correct:     ['neutral' 'neutral' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[1124  123   42]\n",
      " [ 413  408   96]\n",
      " [ 263   94  365]]\n",
      "Accuracy is: 64.788\n",
      "Precision : [ 0.62444444  0.6528      0.72564612]\n",
      "Recall : [ 0.87199379  0.44492912  0.50554017]\n",
      "F1-Score :  [ 0.72774361  0.52918288  0.59591837]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'positive']\n",
      "Correct:     ['negative' 'neutral' 'negative' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[1975  151   77]\n",
      " [ 225  154   50]\n",
      " [  95   23  178]]\n",
      "Accuracy is: 78.791\n",
      "Precision : [ 0.86056645  0.4695122   0.58360656]\n",
      "Recall : [ 0.89650477  0.35897436  0.60135135]\n",
      "F1-Score :  [ 0.87816807  0.40686922  0.59234609]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'positive' ..., 'negative' 'negative' 'negative']\n",
      "Correct:     ['negative' 'negative' 'positive' ..., 'neutral' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1835  186   66]\n",
      " [ 241  186   55]\n",
      " [ 110   40  209]]\n",
      "Accuracy is: 76.161\n",
      "Precision : [ 0.83943275  0.45145631  0.63333333]\n",
      "Recall : [ 0.87925252  0.38589212  0.5821727 ]\n",
      "F1-Score :  [ 0.85888135  0.41610738  0.60667634]\n",
      "Average Accuracy: 73.074\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.89      0.83      9178\n",
      "    neutral       0.56      0.41      0.48      3099\n",
      "   positive       0.67      0.53      0.59      2363\n",
      "\n",
      "avg / total       0.72      0.73      0.72     14640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x = datafr.values[:,1:]                                                     # retweet_count + Doc-Term Matrix\n",
    "y = datafr.values[:,0]                                                      # airline_sentiment\n",
    "kf = KFold(n_splits=5)                                                     # K-Folds = 10 \n",
    "kf.get_n_splits(x)\n",
    "accuracy=[]\n",
    "yt = []\n",
    "yp = []\n",
    "for train_index, test_index in kf.split(x):                                 # For each train and test data\n",
    "    x_train, x_test = x[train_index], x[test_index]                                   \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    sc_x=StandardScaler()\n",
    "    x_train=sc_x.fit_transform(x_train)\n",
    "    x_test=sc_x.transform(x_test)\n",
    "    classifier =RandomForestClassifier(n_estimators = 10, criterion = 'entropy')     # Random Forest Classifier\n",
    "    classifier.fit(x_train,y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    print('===============================================================================')\n",
    "    print('Prediction: ', y_pred)\n",
    "    print('Correct:    ', y_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    acc= accuracy_score(y_test,y_pred)*100\n",
    "    print(\"Accuracy is: %0.3f\" % acc)                                        # Accuracy in each 10 folds\n",
    "    accuracy.append(acc)\n",
    "    pr = precision_score(y_test, y_pred,average=None)\n",
    "    print(\"Precision :\", pr)                                                 # Precision in each 10 folds\n",
    "    recscr = recall_score(y_test, y_pred,average=None)\n",
    "    print(\"Recall :\",  recscr)                                               # Recall in each 10 folds\n",
    "    f1 = f1_score(y_test, y_pred,average=None)\n",
    "    print(\"F1-Score : \",  f1)                                                # F1-Score in each 10 folds\n",
    "    yt += list(y_test)\n",
    "    yp += list(y_pred)\n",
    "\n",
    "avg_accu = np.mean(accuracy)\n",
    "print(\"Average Accuracy: %0.3f\" % avg_accu)                                  # Average Accuracy across 10 folds\n",
    "print(classification_report(yt, yp))                                         # Average Accuracy Precision Recall F1-Score across 10 folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel- Suppport Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'negative']\n",
      "Correct:     ['neutral' 'positive' 'neutral' ..., 'negative' 'negative' 'negative']\n",
      "Confusion Matrix:\n",
      "[[1790   82   27]\n",
      " [ 372  178   35]\n",
      " [ 214   60  170]]\n",
      "Accuracy is: 73.019\n",
      "Precision : [ 0.753367    0.55625     0.73275862]\n",
      "Recall : [ 0.94260137  0.3042735   0.38288288]\n",
      "F1-Score :  [ 0.8374269   0.39337017  0.50295858]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'neutral' 'negative']\n",
      "Correct:     ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1602   68   30]\n",
      " [ 461  191   34]\n",
      " [ 259   63  220]]\n",
      "Accuracy is: 68.750\n",
      "Precision : [ 0.68992248  0.5931677   0.77464789]\n",
      "Recall : [ 0.94235294  0.27842566  0.40590406]\n",
      "F1-Score :  [ 0.7966186   0.37896825  0.53268765]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Correct:     ['neutral' 'neutral' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[1229   49   11]\n",
      " [ 676  205   36]\n",
      " [ 399   49  274]]\n",
      "Accuracy is: 58.333\n",
      "Precision : [ 0.53342014  0.67656766  0.85358255]\n",
      "Recall : [ 0.95345229  0.22355507  0.37950139]\n",
      "F1-Score :  [ 0.68410799  0.33606557  0.52540748]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'neutral' 'negative' ..., 'neutral' 'negative' 'positive']\n",
      "Correct:     ['negative' 'neutral' 'negative' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[2090   79   34]\n",
      " [ 290  114   25]\n",
      " [ 128   26  142]]\n",
      "Accuracy is: 80.123\n",
      "Precision : [ 0.83333333  0.52054795  0.70646766]\n",
      "Recall : [ 0.94870631  0.26573427  0.47972973]\n",
      "F1-Score :  [ 0.88728508  0.35185185  0.57142857]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'positive' ..., 'negative' 'negative' 'negative']\n",
      "Correct:     ['negative' 'negative' 'positive' ..., 'neutral' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1944  118   25]\n",
      " [ 289  173   20]\n",
      " [ 154   35  170]]\n",
      "Accuracy is: 78.108\n",
      "Precision : [ 0.8144114   0.53067485  0.79069767]\n",
      "Recall : [ 0.93148059  0.35892116  0.4735376 ]\n",
      "F1-Score :  [ 0.86902101  0.42821782  0.59233449]\n",
      "Average Accuracy: 71.667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.73      0.94      0.82      9178\n",
      "    neutral       0.58      0.28      0.38      3099\n",
      "   positive       0.78      0.41      0.54      2363\n",
      "\n",
      "avg / total       0.70      0.72      0.68     14640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "x = datafr.values[:,1:]                                                     # retweet_count + Doc-Term Matrix\n",
    "y = datafr.values[:,0]                                                      # airline_sentiment\n",
    "kf = KFold(n_splits=5)                                                     # K-Folds = 10 \n",
    "kf.get_n_splits(x)\n",
    "accuracy=[]\n",
    "yt = []\n",
    "yp = []\n",
    "for train_index, test_index in kf.split(x):                                 # For each train and test data\n",
    "    x_train, x_test = x[train_index], x[test_index]                                   \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    sc_x=StandardScaler()\n",
    "    x_train=sc_x.fit_transform(x_train)\n",
    "    x_test=sc_x.transform(x_test)\n",
    "    classifier =SVC(kernel = 'rbf',random_state=0,degree=2)                 # SVM Classifier\n",
    "    classifier.fit(x_train,y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    print('===============================================================================')\n",
    "    print('Prediction: ', y_pred)\n",
    "    print('Correct:    ', y_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    acc= accuracy_score(y_test,y_pred)*100\n",
    "    print(\"Accuracy is: %0.3f\" % acc)                                        # Accuracy in each 10 folds\n",
    "    accuracy.append(acc)\n",
    "    pr = precision_score(y_test, y_pred,average=None)\n",
    "    print(\"Precision :\", pr)                                                 # Precision in each 10 folds\n",
    "    recscr = recall_score(y_test, y_pred,average=None)\n",
    "    print(\"Recall :\",  recscr)                                               # Recall in each 10 folds\n",
    "    f1 = f1_score(y_test, y_pred,average=None)\n",
    "    print(\"F1-Score : \",  f1)                                                # F1-Score in each 10 folds\n",
    "    yt += list(y_test)\n",
    "    yp += list(y_pred)\n",
    "\n",
    "avg_accu = np.mean(accuracy)\n",
    "print(\"Average Accuracy: %0.3f\" % avg_accu)                                  # Average Accuracy across 10 folds\n",
    "print(classification_report(yt, yp))                                         # Average Accuracy Precision Recall F1-Score across 10 folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k - Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ikshita\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'negative']\n",
      "Correct:     ['neutral' 'positive' 'neutral' ..., 'negative' 'negative' 'negative']\n",
      "Confusion Matrix:\n",
      "[[1442  343  114]\n",
      " [ 341  172   72]\n",
      " [ 216   98  130]]\n",
      "Accuracy is: 59.563\n",
      "Precision : [ 0.72136068  0.28058728  0.41139241]\n",
      "Recall : [ 0.75934702  0.29401709  0.29279279]\n",
      "F1-Score :  [ 0.7398666   0.28714524  0.34210526]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'negative' ..., 'negative' 'neutral' 'neutral']\n",
      "Correct:     ['negative' 'negative' 'negative' ..., 'negative' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1315  296   89]\n",
      " [ 364  265   57]\n",
      " [ 232  139  171]]\n",
      "Accuracy is: 59.802\n",
      "Precision : [ 0.6881214   0.37857143  0.53943218]\n",
      "Recall : [ 0.77352941  0.38629738  0.31549815]\n",
      "F1-Score :  [ 0.7283301   0.38239538  0.39813737]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'positive' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Correct:     ['neutral' 'neutral' 'positive' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[1041  198   50]\n",
      " [ 612  245   60]\n",
      " [ 399  111  212]]\n",
      "Accuracy is: 51.161\n",
      "Precision : [ 0.50730994  0.44223827  0.65838509]\n",
      "Recall : [ 0.80760279  0.26717557  0.29362881]\n",
      "F1-Score :  [ 0.62316672  0.33310673  0.40613027]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'neutral' 'negative' ..., 'negative' 'negative' 'positive']\n",
      "Correct:     ['negative' 'neutral' 'negative' ..., 'negative' 'negative' 'positive']\n",
      "Confusion Matrix:\n",
      "[[1698  399  106]\n",
      " [ 266  138   25]\n",
      " [ 136   54  106]]\n",
      "Accuracy is: 66.325\n",
      "Precision : [ 0.80857143  0.23350254  0.44725738]\n",
      "Recall : [ 0.77076714  0.32167832  0.35810811]\n",
      "F1-Score :  [ 0.78921683  0.27058824  0.39774859]\n",
      "===============================================================================\n",
      "Prediction:  ['negative' 'negative' 'positive' ..., 'neutral' 'neutral' 'neutral']\n",
      "Correct:     ['negative' 'negative' 'positive' ..., 'neutral' 'negative' 'neutral']\n",
      "Confusion Matrix:\n",
      "[[1604  402   81]\n",
      " [ 264  190   28]\n",
      " [ 160   74  125]]\n",
      "Accuracy is: 65.540\n",
      "Precision : [ 0.79092702  0.28528529  0.53418803]\n",
      "Recall : [ 0.76856732  0.39419087  0.34818942]\n",
      "F1-Score :  [ 0.77958688  0.33101045  0.42158516]\n",
      "Average Accuracy: 60.478\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.70      0.77      0.74      9178\n",
      "    neutral       0.32      0.33      0.32      3099\n",
      "   positive       0.52      0.31      0.39      2363\n",
      "\n",
      "avg / total       0.59      0.60      0.59     14640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "x = datafr.values[:,1:]                                                     # retweet_count + Doc-Term Matrix\n",
    "y = datafr.values[:,0]                                                      # airline_sentiment\n",
    "kf = KFold(n_splits=5)                                                     # K-Folds = 10 \n",
    "kf.get_n_splits(x)\n",
    "accuracy=[]\n",
    "yt = []\n",
    "yp = []\n",
    "for train_index, test_index in kf.split(x):                                 # For each train and test data\n",
    "    x_train, x_test = x[train_index], x[test_index]                                   \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    sc_x=StandardScaler()\n",
    "    x_train=sc_x.fit_transform(x_train)\n",
    "    x_test=sc_x.transform(x_test)\n",
    "    classifier =KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)                 # k-NN Classifier\n",
    "    classifier.fit(x_train,y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    print('===============================================================================')\n",
    "    print('Prediction: ', y_pred)\n",
    "    print('Correct:    ', y_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    acc= accuracy_score(y_test,y_pred)*100\n",
    "    print(\"Accuracy is: %0.3f\" % acc)                                        # Accuracy in each 10 folds\n",
    "    accuracy.append(acc)\n",
    "    pr = precision_score(y_test, y_pred,average=None)\n",
    "    print(\"Precision :\", pr)                                                 # Precision in each 10 folds\n",
    "    recscr = recall_score(y_test, y_pred,average=None)\n",
    "    print(\"Recall :\",  recscr)                                               # Recall in each 10 folds\n",
    "    f1 = f1_score(y_test, y_pred,average=None)\n",
    "    print(\"F1-Score : \",  f1)                                                # F1-Score in each 10 folds\n",
    "    yt += list(y_test)\n",
    "    yp += list(y_pred)\n",
    "\n",
    "avg_accu = np.mean(accuracy)\n",
    "print(\"Average Accuracy: %0.3f\" % avg_accu)                                  # Average Accuracy across 10 folds\n",
    "print(classification_report(yt, yp))                                         # Average Accuracy Precision Recall F1-Score across 10 folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
